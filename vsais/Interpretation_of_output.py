# 精确率的分母：四个list对应四个类别，每个list中值分别对应置信度为0，0.05，0.1，0.15，0.2，0.25..........0.9，0.95的检测到的个数
precision_denominator = [
    [1649, 1649, 1649, 1649, 1649, 1649, 1649, 1649, 1649, 1649, 1649, 1649, 1649, 1649, 1649, 1649, 1649, 1619, 1567, 1489],
    [389, 389, 389, 389, 389, 389, 389, 389, 389, 389, 389, 389, 389, 389, 389, 389, 389, 365, 340, 294],
    [946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 884, 816, 698],
    [118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 108, 103, 79]
]
# 召回率的分母：一个list中的四个值分别对应四个类的标注标签的个数
recall_denominator = [1672, 414, 1105, 109]
######################################## 这个注释掉的内容是都打印的，和精确率的分子是一个意思
# result_precision_num = [
#     [[1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1402, 1363,
#       1299],
#      [324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 307, 285, 249],
#      [817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 767, 709, 606],
#      [92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 86, 83, 64]],
#     [[1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1402, 1363,
#       1299],
#      [321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 306, 285, 249],
#      [809, 809, 809, 809, 809, 809, 809, 809, 809, 809, 809, 809, 809, 809, 809, 809, 809, 762, 706, 606],
#      [92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 86, 83, 64]],
#     [[1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1402, 1363,
#       1299],
#      [324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 307, 285, 249],
#      [817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 767, 709, 606],
#      [92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 86, 83, 64]]]
# 精确率的分子：第二层的三个list对应三个iou值，0.2、0.25、0.5，自己要求生成的三个iou值，如果只选择一个，它就只有一个。
# 第三层的list对应四个类别，每个list中值分别对应置信度为0，0.05，0.1，0.15，0.2，0.25..........0.9，0.95的检测正确的个数（数据计算方式是以detect_truth为基数，从ground_truth里面找,置信度符合且iou符合，数目就加1，这样计算不会有大于一的情况出现）
precision_numerator = [
    [[1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1402, 1363, 1299],
     [324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 307, 285, 249],
     [817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 767, 709, 606],
     [92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 86, 83, 64]],
    [[1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1402, 1363, 1299],
     [321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 306, 285, 249],
     [809, 809, 809, 809, 809, 809, 809, 809, 809, 809, 809, 809, 809, 809, 809, 809, 809, 762, 706, 606],
     [92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 86, 83, 64]],
    [[1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1402, 1363, 1299],
     [324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 307, 285, 249],
     [817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 817, 767, 709, 606],
     [92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 86, 83, 64]]
]
######################################## 这个注释掉的内容是都打印的，和召回率的分子是一个意思
# recall_recall_result = [
#     [[1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424,1424, 1402, 1367, 1304],
#      [321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 305, 284, 248],
#      [811, 811, 811, 811, 811, 811, 811, 811, 811, 811, 811, 811, 811, 811, 811, 811, 811, 762, 708, 607],
#      [92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 86, 83, 64]],
#     [[1423, 1423, 1423, 1423, 1423, 1423, 1423, 1423, 1423, 1423, 1423, 1423, 1423, 1423, 1423, 1423, 1423, 1401, 1365, 1303],
#      [321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 305, 284, 248],
#      [810, 810, 810, 810, 810, 810, 810, 810, 810, 810, 810, 810, 810, 810, 810, 810, 810, 761, 707, 606],
#      [92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 86, 83, 64]],
#     [[1421, 1421, 1421, 1421, 1421, 1421, 1421, 1421, 1421, 1421, 1421, 1421, 1421, 1421, 1421, 1421, 1421, 1400, 1363, 1300],
#      [320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 305, 284, 248],
#      [806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 759, 705, 606],
#      [92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 86, 83, 64]]
# ]
# 召回率的分子：第二层的三个list对应三个iou值，0.2、0.25、0.5，自己要求生成的三个iou值，如果只选择一个，它就只有一个。
# 第三层的list对应四个类别，每个list中值分别对应置信度为0，0.05，0.1，0.15，0.2，0.25..........0.9，0.95的检测正确的个数（数据计算方式是以ground_truth为基数，从detect_truth里面找,置信度符合且iou符合，数目就加1，这样计算不会有大于一的情况出现）
recall_numerator = [
    [[1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1402, 1367, 1304],
     [321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 305, 284, 248],
     [811, 811, 811, 811, 811, 811, 811, 811, 811, 811, 811, 811, 811, 811, 811, 811, 811, 762, 708, 607],
     [92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 86, 83, 64]],
    [[1423, 1423, 1423, 1423, 1423, 1423, 1423, 1423, 1423, 1423, 1423, 1423, 1423, 1423, 1423, 1423, 1423, 1401, 1365, 1303],
     [321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 305, 284, 248],
     [810, 810, 810, 810, 810, 810, 810, 810, 810, 810, 810, 810, 810, 810, 810, 810, 810, 761, 707, 606],
     [92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 86, 83, 64]],
    [[1421, 1421, 1421, 1421, 1421, 1421, 1421, 1421, 1421, 1421, 1421, 1421, 1421, 1421, 1421, 1421, 1421, 1400, 1363, 1300],
     [320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 305, 284, 248],
     [806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 759, 705, 606],
     [92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 86, 83, 64]]
                    ]

# iou 0.2
# list中值分别对应置信度为0，0.05，0.1，0.15，0.2，0.25..........0.9，0.95时候，iou为0.2，计算得到的召回率的大小    recall = （A类符合iou和置信度的正确个数/A类所有的ground_truth+.......D类符合iou和置信度的正确个数/D类所有的ground_truth）/4
recall1 = [0.8012525772050805, 0.8012525772050805, 0.8012525772050805, 0.8012525772050805, 0.8012525772050805,
          0.8012525772050805, 0.8012525772050805, 0.8012525772050805, 0.8012525772050805, 0.8012525772050805,
          0.8012525772050805, 0.8012525772050805, 0.8012525772050805, 0.8012525772050805, 0.8012525772050805,
          0.8012525772050805, 0.8012525772050805, 0.7634538270314908, 0.7264414855075942, 0.6288538382290736]
# list中值分别对应置信度为0，0.05，0.1，0.15，0.2，0.25..........0.9，0.95时候，iou为0.2，计算得到的精确率的大小    precision = (A类符合iou和置信度的正确个数/所有的detect_truth+.......D类符合iou和置信度的正确个数/D类所有的detect_truth)/4
precision1 = [0.8349389834486297, 0.8349389834486297, 0.8349389834486297, 0.8349389834486297, 0.8349389834486297,
             0.8349389834486297, 0.8349389834486297, 0.8349389834486297, 0.8349389834486297, 0.8349389834486297,
             0.8349389834486297, 0.8349389834486297, 0.8349389834486297, 0.8349389834486297, 0.8349389834486297,
             0.8349389834486297, 0.8349389834486297, 0.8427514729021526, 0.8456870047121705, 0.8494144456163855]
# list中值分别对应置信度为0，0.05，0.1，0.15，0.2，0.25..........0.9，0.95时候，iou为0.2，计算得到的f1-score的大小 f1-socre = 2*precision*recall/(precision+recall)
# 模型总的f1-score = （A类的f1-socre+....D类的f1-score）/4     这个方式没法说他错，但是有误差，网络上的算法不是这么算的，网络上算的会比侯算的大一个点
f1score1 = [0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.8, 0.78, 0.72]


##########################################下同iou等于2，就不做介绍了
# iou 0.25
recall2 = [0.8012525772050805, 0.8012525772050805, 0.8012525772050805, 0.8012525772050805, 0.8012525772050805,
          0.8012525772050805, 0.8012525772050805, 0.8012525772050805, 0.8012525772050805, 0.8012525772050805,
          0.8012525772050805, 0.8012525772050805, 0.8012525772050805, 0.8012525772050805, 0.8012525772050805,
          0.8012525772050805, 0.8012525772050805, 0.7634538270314908, 0.7264414855075942, 0.6288538382290736]
precision2 = [0.8349389834486297, 0.8349389834486297, 0.8349389834486297, 0.8349389834486297, 0.8349389834486297,
             0.8349389834486297, 0.8349389834486297, 0.8349389834486297, 0.8349389834486297, 0.8349389834486297,
             0.8349389834486297, 0.8349389834486297, 0.8349389834486297, 0.8349389834486297, 0.8349389834486297,
             0.8349389834486297, 0.8349389834486297, 0.8427514729021526, 0.8456870047121705, 0.8494144456163855]
f1score2 = [0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.8, 0.78, 0.72]
# iou 0.5
recall3 = [0.8012525772050805, 0.8012525772050805, 0.8012525772050805, 0.8012525772050805, 0.8012525772050805,
          0.8012525772050805, 0.8012525772050805, 0.8012525772050805, 0.8012525772050805, 0.8012525772050805,
          0.8012525772050805, 0.8012525772050805, 0.8012525772050805, 0.8012525772050805, 0.8012525772050805,
          0.8012525772050805, 0.8012525772050805, 0.7634538270314908, 0.7264414855075942, 0.6288538382290736]
precision3 = [0.8349389834486297, 0.8349389834486297, 0.8349389834486297, 0.8349389834486297, 0.8349389834486297,
             0.8349389834486297, 0.8349389834486297, 0.8349389834486297, 0.8349389834486297, 0.8349389834486297,
             0.8349389834486297, 0.8349389834486297, 0.8349389834486297, 0.8349389834486297, 0.8349389834486297,
             0.8349389834486297, 0.8349389834486297, 0.8427514729021526, 0.8456870047121705, 0.8494144456163855]
f1score3 = [0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.8, 0.78, 0.72]
